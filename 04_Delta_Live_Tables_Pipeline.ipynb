{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0122de0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **Notebook 4: Delta Live Tables for Incremental Updates**\n",
    "\n",
    "#### Steps:\n",
    "1. Use Bronze and Silver Delta tables as input for DLT.\n",
    "2. Update the Silver and Gold layers incrementally.\n",
    "\n",
    "#### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14968299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "# Bronze Table\n",
    "@dlt.table\n",
    "def bronze_retail_data():\n",
    "    return spark.read.format(\"delta\").load(\"/mnt/s3data/bronze/retail_data\")\n",
    "\n",
    "# Silver Table\n",
    "@dlt.table\n",
    "def silver_retail_data():\n",
    "    return dlt.read(\"bronze_retail_data\").filter(col(\"transaction_amount\").isNotNull())\n",
    "\n",
    "# Gold Table\n",
    "@dlt.table\n",
    "def gold_retail_data():\n",
    "    existing_gold = spark.read.format(\"delta\").load(\"/mnt/s3data/gold/retail_data\")\n",
    "    new_aggregates = (dlt.read(\"silver_retail_data\")\n",
    "                      .groupBy(\"region\", \"year\")\n",
    "                      .agg(sum(\"transaction_amount\").alias(\"total_sales\")))\n",
    "    return existing_gold.union(new_aggregates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d9058",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
